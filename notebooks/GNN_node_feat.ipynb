{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "#print(torch.__version__)\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random as rd \n",
    "from torch.nn import Softmax\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "from torch.nn import Linear\n",
    "from torch.nn import Softmax\n",
    "import torch.nn.functional as F\n",
    "#from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.nn import global_mean_pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels,n_hidden_convlayers):\n",
    "        super(GNN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        \n",
    "        num_node_features = 4 #change\n",
    "        output = 2\n",
    "        self.n_hidden_convlayers = n_hidden_convlayers\n",
    "        # edge embedding\n",
    "        \n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for k in range(n_hidden_convlayers):\n",
    "            if k == 0:\n",
    "                self.hidden_layers.append( GraphConv(num_node_features, hidden_channels))\n",
    "            else:\n",
    "                self.hidden_layers.append( GraphConv(hidden_channels, hidden_channels))\n",
    "\n",
    "        # global embedding \n",
    "        self.lin5 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin6 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin7 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin8 = Linear(hidden_channels, hidden_channels)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, output)\n",
    "\n",
    "\n",
    "    def forward(self,node_attr,edge_index, batch):\n",
    "        # 1. Obtain edge embeddings \n",
    "        for k in range(self.n_hidden_convlayers):\n",
    "            node_attr = self.hidden_layers[k](node_attr,edge_index)\n",
    "            node_attr = node_attr.relu()\n",
    "\n",
    "        # 2. Readout layer\n",
    "        node_attr = global_mean_pool(node_attr, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        node_attr = F.dropout(node_attr, p=0.5, training=self.training)\n",
    "        node_attr = self.lin5(node_attr)\n",
    "        node_attr = node_attr.relu()\n",
    "        node_attr = self.lin6(node_attr)\n",
    "        node_attr = node_attr.relu()\n",
    "        node_attr = self.lin7(node_attr)\n",
    "        node_attr = node_attr.relu()\n",
    "        node_attr = self.lin8(node_attr)\n",
    "        node_attr = node_attr.relu()\n",
    "        node_attr = self.lin(node_attr)\n",
    "        #node_attr = Softmax(dim=1)(node_attr)\n",
    "        node_attr = torch.sigmoid(node_attr)\n",
    "        \n",
    "        return node_attr\n",
    "\n",
    "from IPython.display import Javascript\n",
    "#display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_leafs = 20\n",
    "t_max = 300\n",
    "model = GNN(hidden_channels=50, n_hidden_convlayers=int(0.4*(nb_leafs-1)))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "criterion = torch.nn.L1Loss(reduction='sum')\n",
    "\n",
    "import json\n",
    "\n",
    "# Open the file and read the contents\n",
    "with open('dataset10k_v2.txt', 'r') as file: #'/workdir/chirraneso/dataset10k.txt'\n",
    "    contents = file.read()\n",
    "\n",
    "# Parse the contents as JSON and convert it to a Python dictionary\n",
    "data_dict = json.loads(contents)\n",
    "n= len(data_dict['p0'])\n",
    "print(\"n\",n)\n",
    "train_size = int(0.8*n)\n",
    "print(\"train\", train_size)\n",
    "#shuffle index of the dataset \n",
    "index = [k for k in range(n)]\n",
    "shuffle(index)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for k in index[0:train_size]:  # Iterate in batches over the training dataset.\n",
    "        p2,p0 = data_dict['p2'][k],data_dict['p0'][k]\n",
    "        #simu = simulator(p0,p2, nb_leafs,t_max)\n",
    "        if type(data_dict[\"dyck\"][k]) != int : \n",
    "            values = data_dict[\"coo\"][k][0]\n",
    "            features = np.array(data_dict['node_features'][k])\n",
    "            row = data_dict[\"coo\"][k][1] \n",
    "            col = data_dict[\"coo\"][k][2] \n",
    "            coo = torch.LongTensor([row,col])\n",
    "            data = Data(edge_index = coo, y= torch.tensor([[p0/p2,p2-p0]]), num_nodes = 2*nb_leafs-1,edge_attr = torch.tensor([values+[0]]).T,  x=torch.tensor(np.vstack((features,np.zeros(4)))).float()) #[p0,1-(p2 +p0),p2]\n",
    "            out = model(data.x,data.edge_index, data.batch) # Perform a single forward pass. #CHANGE\n",
    "            loss = criterion(out, data.y)  # Compute the loss.\n",
    "            loss.backward()  # Derive gradients.\n",
    "            optimizer.step()  # Update parameters based on gradients.\n",
    "            optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    MSE =0\n",
    "    error_delta = 0\n",
    "    error_q =0\n",
    "    error_p0 =0\n",
    "    error_p2 = 0\n",
    "\n",
    "    for k in index[train_size:n]:  # Iterate in batches over the training dataset.\n",
    "        p2,p0 = data_dict['p2'][k],data_dict['p0'][k]\n",
    "        #simu = simulator(p0,p2, nb_leafs,t_max)\n",
    "        if type(data_dict[\"dyck\"][k]) != int: \n",
    "            values = data_dict[\"coo\"][k][0]\n",
    "            features = np.array(data_dict['node_features'][k])\n",
    "            row = data_dict[\"coo\"][k][1] \n",
    "            col = data_dict[\"coo\"][k][2] \n",
    "            coo = torch.LongTensor([row,col])\n",
    "            data = Data(edge_index = coo, y= torch.tensor([[p0/p2,p2-p0]]), num_nodes = 2*nb_leafs-1, edge_attr = torch.tensor([values+[0]]).T, x=torch.tensor(np.vstack((features,np.zeros(4)))).float())\n",
    "            out = model(data.x,data.edge_index, data.batch) # Perform a single forward pass. #CHANGE\n",
    "            distance = criterion(out, data.y)  # Compute the loss.\n",
    "            out = out[0]\n",
    "            data.y = data.y[0]\n",
    "            error_q += abs(out[0] -data.y[0])/data.y[0]\n",
    "            error_delta += abs(out[1] -data.y[1])/data.y[1]\n",
    "            error_p2 += abs(out[1]/(1-out[0]) - p2)/p2\n",
    "            error_p0 += abs(out[0]*out[1]/(1-out[0]) - p0)/p0\n",
    "            MSE += distance\n",
    "    return MSE/(n-train_size), error_q/(n-train_size), error_delta/(n-train_size), error_p2/(n-train_size), error_p0/(n-train_size)\n",
    "\n",
    "\n",
    "report = open(\"report_GNN_node_features.txt\",\"w+\")\n",
    "report.write(f'leafs:{nb_leafs}\\n')\n",
    "report.write(f'tmax:{t_max}\\n')\n",
    "report.write(f'trainsize:{train_size}\\n')\n",
    "\n",
    "for epoch in range(1, 2):\n",
    "    train()\n",
    "    MSE, error_q, error_delta, error_p2, error_p0 = test()\n",
    "    report.write(f'Epoch: {epoch:03d}, Test MSE: {MSE:.4f}, Test error q: {error_q:.4f},Test error delat: {error_delta:.4f},Test error p2: {error_p2:.4f}, Test error p0: {error_p0:.4f} \\n')\n",
    "    print(f'Epoch: {epoch:03d}, Test MSE: {MSE:.4f}, Test error q: {error_q:.4f},Test error delat: {error_delta:.4f},Test error p2: {error_p2:.4f}, Test error p0: {error_p0:.4f} ')\n",
    "\n",
    "report.close()\n",
    "\n",
    "torch.save(model,\"model_GNN_nodefeat\") #model = torch.load('model_DNN') to load"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
